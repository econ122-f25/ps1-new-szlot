---
title: "Problem Set 1"
author: "Your Name"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

### Introduction

This problem set is designed to test your understanding of data wrangling concepts using the **`tidyverse`**, specifically **`dplyr`** and **`tidyr`**, as well as foundational R concepts. You'll primarily work with the `mtcars`, a simulated sales dataset, and new simulated student demographic/grade datasets, applying core verbs and functions to prepare data for analysis. This activity should take approximately 60 minutes.

### Instructions

* Read each task carefully.
* Write your R code in the provided code chunks.
* Run the code to see your output and verify your results.
* `mtcars` is a built-in R dataset (or part of the `tidyverse` installation).

---

## Part 0: R Fundamentals (10 minutes)

This section will test your understanding of basic R syntax, data types, and vector operations.

### Task 0.1: Data Types and Logical Operations

1.  Create a variable `course_name` and assign it the string `"Introduction to Data Science"`.
2.  Create a variable `num_students` and assign it the integer value `45`.
3.  Check the data type (`class()`) of `course_name` and `num_students`.
4.  Create a numeric variable `pi_value` with the value $3.14159$.
5.  Create a logical variable `is_active` and set it to `TRUE`.
6.  Evaluate the following logical expressions and print their results:
    * Is `num_students` greater than or equal to `50`?
    * Is `course_name` exactly equal to `"introduction to data science"` (case-sensitive)?

```{r}
# Your code here
```

---

### Task 0.2: Working with Vectors

1.  Create a numeric vector named `temperatures` with the values $22, 25, 19, 28, 23$.
2.  Calculate the `sum()` and `mean()` of the `temperatures` vector.
3.  Add a new temperature, $30$, to the `temperatures` vector (re-assign the variable).
4.  Create a new logical vector named `is_hot` that is `TRUE` for temperatures greater than $25$ and `FALSE` otherwise.

```{r}
# Your code here
```

---

## Part 1: `dplyr` Fundamentals with `mtcars` (25 minutes)

This section focuses on applying core `dplyr` verbs to the classic `mtcars` dataset. The `mtcars` dataset contains information about various car models from 1973-74.

### Task 1.1: Filtering and Arranging

1.  The `mtcars` dataset has been pre-processed for you to include `car_model` as a column.
2.  Filter the dataset to include only cars with `cyl` (number of cylinders) equal to `4` or `6` AND `mpg` (miles per gallon) greater than `20`.
3.  Arrange the results first by `mpg` in ascending order, and then by `cyl` in descending order.

```{r}
# Pre-processing step: Convert rownames to car_model
mtcars_processed <- mtcars %>%
  rownames_to_column("car_model")

# Your code starts here: Filter and arrange mtcars_processed
# Your code here
```

### Short Answer
Based on your filtered and arranged results, briefly describe the characteristics of the cars that appear at the top of your output. What does this tell you about the relationship between cylinders and miles per gallon in this subset?

---

### Task 1.2: Mutating and Selecting

Using the `mtcars_processed` dataset:

1.  Create a new column `hp_per_wt` by dividing `hp` (horsepower) by `wt` (weight in 1000 lbs).
2.  Create another new column `qsec_category` based on `qsec` (1/4 mile time):
    * `"Fast"` if `qsec < 17`
    * `"Medium"` if `qsec >= 17` and `qsec < 19`
    * `"Slow"` if `qsec >= 19`
3.  Select only the `car_model`, `mpg`, `hp`, `wt`, `hp_per_wt`, and `qsec_category` columns.

```{r}
# Your code here
```

### Short Answer
Why might creating `hp_per_wt` and `qsec_category` be useful metrics when analyzing car performance, beyond just raw horsepower and weight?

---

### Task 1.3: Grouped Summaries

Using the `mtcars_processed` dataset:

1.  Group the data by `cyl` (number of cylinders) and `am` (transmission type: 0 for automatic, 1 for manual).
2.  For each group, calculate the **average `mpg`**, the **median `hp`**, and the **number of cars** (`n()`).
3.  Arrange the final result first by `cyl` (ascending) and then by `average_mpg` (descending).

```{r}
# Your code here
```

### Short Answer
Based on your grouped summary, what general trends do you observe regarding average `mpg` and median `hp` across different combinations of `cylinders` and `transmission` types? How do these summaries help differentiate car characteristics?

---

## Part 2: Reshaping and Joining Data (25 minutes)

For this part, we'll explore reshaping and joining using a simulated sales dataset and new simulated student enrollment data.

**Run this code chunk first to set up the data:**

```{r, echo = TRUE}
# Part 2 Data Setup
product_sales_wide <- tibble(
  product = c("Laptop", "Monitor", "Keyboard"),
  `2020` = c(1000, 500, 800),
  `2021` = c(1100, 550, 850),
  `2022` = c(1250, 600, 900)
) %>%
  rename(Year_2020 = `2020`, Year_2021 = `2021`, Year_2022 = `2022`) # Rename to avoid issues with non-syntactic names

# Simulated Student and Grade Data
students_demographics <- tibble(
  student_id = c("S001", "S002", "S003", "S004", "S005", "S007"), # S007 is a new student, no grades yet
  student_name = c("Alice", "Bob", "Charlie", "David", "Eve", "Frank"),
  major = c("CS", "Math", "Physics", "CS", "Biology", "History"),
  enrollment_year = c(2020, 2021, 2020, 2022, 2021, 2023)
)

student_grades <- tibble(
  student_id = c("S001", "S002", "S003", "S001", "S006", "S004"), # S006 has grades but no demographic info
  course_id = c("CS101", "MA201", "PH301", "CS102", "BI101", "CS205"),
  semester = c("Fall 2020", "Spring 2022", "Fall 2021", "Spring 2021", "Fall 2021", "Spring 2023"),
  grade_score = c(92, 85, 88, 78, 75, 90) # Assuming numeric scores for easier calculation
)

# Display the dataframes
print(product_sales_wide)
print(students_demographics)
print(student_grades)
```

---

### Task 2.1: New Variable Creation: Wide vs. Long (`product_sales` dataset)

This task demonstrates how creating new variables that depend on previous time periods is much easier in a long (tidy) format.

1.  **Analysis in Wide Format:** Using the `product_sales_wide` dataset, create new columns for the **year-over-year growth rate** for 2021 and 2022.
    * `Growth_2021`: `(Year_2021 - Year_2020) / Year_2020 * 100`
    * `Growth_2022`: `(Year_2022 - Year_2021) / Year_2021 * 100`

```{r}
# Your code here
```

2.  **Reshape to Long Format:** Reshape `product_sales_wide` into a long format called `product_sales_long`. Pivot the year columns (`Year_2020`, `Year_2021`, `Year_2022`) into two new columns: `Year` and `Sales`. Make sure `Year` is numeric.

```{r}
# Your code here
```
3.  **Analysis in Long Format:** Using the `product_sales_long` dataset, calculate a single `Growth_Rate` column that represents the year-over-year growth for each product. You should use `group_by()` and `lag()`. The formula for growth rate is `(current_year_sales - previous_year_sales) / previous_year_sales * 100`.

```{r}
# Your code here
```

### Short Answer
Compare the code required to calculate the year-over-year growth rate in the wide format versus the long format. Which approach is more concise and scalable if you had many more years of data? Why is the long format generally preferred for this type of time-series calculation?

---

### Task 2.2: Mutating Joins: Student Demographics and Grades

This task explores combining student demographic information with their academic performance. Pay close attention to how different join types handle students who may or may not have corresponding grade records.

1.  **Inner Join:** Perform an `inner_join()` to combine `students_demographics` with `student_grades` based on `student_id`. This will show students who have **both** demographic information and at least one grade record.
2.  **Left Join:** Perform a `left_join()` to combine `students_demographics` (left table) with `student_grades` based on `student_id`. This will keep **all students** from the demographic data and add their grade records where available.
3.  **Advanced Mutate (after Left Join):** After performing the left join, calculate the **average `grade_score` for each student**. This will require grouping by `student_id` and `student_name`.

```{r}
# Your code for inner_join and its explanation
```{r}
# Your code for left_join and its explanation
```{r}
# Your code for advanced mutate after left join
```

### Short Answer
Compare the number of rows and the content of the `inner_join()` and `left_join()` results. Specifically, identify which student(s) are present in one join but not the other, and explain why. What does the average grade calculation reveal about students with multiple grades or no grades?

---

### Task 2.3: Filtering Joins: Identifying Student Enrollment Status

This task focuses on using filtering joins to identify different categories of students based on their enrollment and grade records.

1.  **Enrolled Students:** Use a `semi_join()` to identify which students from `students_demographics` are actually enrolled in and have a grade record in `student_grades`. This should return only columns from `students_demographics`.
2.  **Students Without Grades:** Use an `anti_join()` to identify which students from `students_demographics` are in the system but currently do *not* have any grade records in `student_grades` (e.g., new students, or those who haven't completed courses yet). This should return only columns from `students_demographics`.
3.  **Grades Without Students:** Use an `anti_join()` to identify any grade records in `student_grades` that do *not* correspond to an existing student in `students_demographics` (e.g., a data entry error or a record for a past student no longer in the demographic system). This should return only columns from `student_grades`.

```{r}
# Your code for question 1 (semi_join)
```{r}
# Your code for question 2 (anti_join on students_demographics)
```{r}
# Your code for question 3 (anti_join on student_grades)
```

### Short Answer
Describe the distinct insights gained from each of the three filtering joins in this task. How do these joins help in data validation and understanding the completeness of your student records?



