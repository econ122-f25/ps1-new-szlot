---
title: "Problem Set 1"
author: "Sam Zlot"
date: "`r Sys.Date(9/10/25)`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

### Introduction

This problem set is designed to test your understanding of data wrangling concepts using the **`tidyverse`**, specifically **`dplyr`** and **`tidyr`**, as well as foundational R concepts. You'll primarily work with the `mtcars`, a simulated sales dataset, and new simulated student demographic/grade datasets, applying core verbs and functions to prepare data for analysis. This activity should take approximately 60 minutes.

### Instructions

* Read each task carefully.
* Write your R code in the provided code chunks.
* Run the code to see your output and verify your results.
* `mtcars` is a built-in R dataset (or part of the `tidyverse` installation).

---

## Part 0: R Fundamentals (10 minutes)

This section will test your understanding of basic R syntax, data types, and vector operations.

### Task 0.1: Data Types and Logical Operations

1.  Create a variable `course_name` and assign it the string `"Introduction to Data Science"`.
2.  Create a variable `num_students` and assign it the integer value `45`.
3.  Check the data type (`class()`) of `course_name` and `num_students`.
4.  Create a numeric variable `pi_value` with the value $3.14159$.
5.  Create a logical variable `is_active` and set it to `TRUE`.
6.  Evaluate the following logical expressions and print their results:
    * Is `num_students` greater than or equal to `50`?
    * Is `course_name` exactly equal to `"introduction to data science"` (case-sensitive)?

```{r}
course_name <- "Introduction to Data Science"
num_students <- 45
class(course_name)
class(num_students)
pi_value <- 3.14159
is_active = TRUE
num_students >= 50
course_name == "introduction to data sciene"
```

---

### Task 0.2: Working with Vectors

1.  Create a numeric vector named `temperatures` with the values $22, 25, 19, 28, 23$.
2.  Calculate the `sum()` and `mean()` of the `temperatures` vector.
3.  Add a new temperature, $30$, to the `temperatures` vector (re-assign the variable).
4.  Create a new logical vector named `is_hot` that is `TRUE` for temperatures greater than $25$ and `FALSE` otherwise.

```{r}
temperatures <- c(22, 25, 19, 28, 23)
sum(temperatures)
mean(temperatures)
temperatures <- c(22, 25, 19, 28, 30)
is_hot <- temperatures > 25
temperatures
is_hot
```

---

## Part 1: `dplyr` Fundamentals with `mtcars` (25 minutes)

This section focuses on applying core `dplyr` verbs to the classic `mtcars` dataset. The `mtcars` dataset contains information about various car models from 1973-74.

### Task 1.1: Filtering and Arranging

1.  The `mtcars` dataset has been pre-processed for you to include `car_model` as a column.
2.  Filter the dataset to include only cars with `cyl` (number of cylinders) equal to `4` or `6` AND `mpg` (miles per gallon) greater than `20`.
3.  Arrange the results first by `mpg` in ascending order, and then by `cyl` in descending order.

```{r}

mtcars_processed <- mtcars %>%
  rownames_to_column("car_model")

mtcars %>% filter(cyl == 4 & mpg > 20)
mtcars %>% arrange(mpg, desc(cyl))
```

### Short Answer
Based on your filtered and arranged results, briefly describe the characteristics of the cars that appear at the top of your output. What does this tell you about the relationship between cylinders and miles per gallon in this subset?

Having only four cylinders results in a more fuel efficient car since engine is lighter and has less capabilities. Rather for the eight cylinder cars the fuel efficiency is much less due to the heavier and stronger engine. 
---

### Task 1.2: Mutating and Selecting

Using the `mtcars_processed` dataset:

1.  Create a new column `hp_per_wt` by dividing `hp` (horsepower) by `wt` (weight in 1000 lbs).
2.  Create another new column `qsec_category` based on `qsec` (1/4 mile time):
    * `"Fast"` if `qsec < 17`
    * `"Medium"` if `qsec >= 17` and `qsec < 19`
    * `"Slow"` if `qsec >= 19`
3.  Select only the `car_model`, `mpg`, `hp`, `wt`, `hp_per_wt`, and `qsec_category` columns.

```{r}
mtcars %>% 
  mutate(
    hp_per_wt = hp / wt,
    qsec_category = ifelse(qsec < 17, "Fast",
                     ifelse(qsec >= 17 & qsec < 19, "Medium",
                     ifelse(qsec >= 19, "Slow", NA)))
  ) %>%

select( mpg, hp, wt, hp_per_wt, qsec_category)
```

### Short Answer
Why might creating `hp_per_wt` and `qsec_category` be useful metrics when analyzing car performance, beyond just raw horsepower and weight?

Horse power divided by weight is helpful since usually a bigger engine that provides more horse power weighs more so can see pound for pound the most powerful car. The qsec for category just makes it easier to comprehend how fast the car is for someone not knowledgeable of how fast cars are for a quarter mile time.
---

### Task 1.3: Grouped Summaries

Using the `mtcars_processed` dataset:

1.  Group the data by `cyl` (number of cylinders) and `am` (transmission type: 0 for automatic, 1 for manual).
2.  For each group, calculate the **average `mpg`**, the **median `hp`**, and the **number of cars** (`n()`).
3.  Arrange the final result first by `cyl` (ascending) and then by `average_mpg` (descending).

```{r}
mtcars %>%
  group_by(cyl, am)%>% 
  summarise(
    average_mpg = mean(mpg, na.rm = TRUE),
    median_hp = median(hp, na.rm = TRUE),
    number_cars = n()
  ) %>%
arrange(cyl, desc(average_mpg))

```

### Short Answer
Based on your grouped summary, what general trends do you observe regarding average `mpg` and median `hp` across different combinations of `cylinders` and `transmission` types? How do these summaries help differentiate car characteristics?

What I noticed is that the less cylinders leads to higher mpg but also less horse power. I noticed too for each type manual car for the same cylinders has more fuel efficiency. 
---

## Part 2: Reshaping and Joining Data (25 minutes)

For this part, we'll explore reshaping and joining using a simulated sales dataset and new simulated student enrollment data.

**Run this code chunk first to set up the data:**

```{r, echo = TRUE}
# Part 2 Data Setup
product_sales_wide <- tibble(
  product = c("Laptop", "Monitor", "Keyboard"),
  `2020` = c(1000, 500, 800),
  `2021` = c(1100, 550, 850),
  `2022` = c(1250, 600, 900)
) %>%
  rename(Year_2020 = `2020`, Year_2021 = `2021`, Year_2022 = `2022`) # Rename to avoid issues with non-syntactic names

# Simulated Student and Grade Data
students_demographics <- tibble(
  student_id = c("S001", "S002", "S003", "S004", "S005", "S007"), # S007 is a new student, no grades yet
  student_name = c("Alice", "Bob", "Charlie", "David", "Eve", "Frank"),
  major = c("CS", "Math", "Physics", "CS", "Biology", "History"),
  enrollment_year = c(2020, 2021, 2020, 2022, 2021, 2023)
)

student_grades <- tibble(
  student_id = c("S001", "S002", "S003", "S001", "S006", "S004"), # S006 has grades but no demographic info
  course_id = c("CS101", "MA201", "PH301", "CS102", "BI101", "CS205"),
  semester = c("Fall 2020", "Spring 2022", "Fall 2021", "Spring 2021", "Fall 2021", "Spring 2023"),
  grade_score = c(92, 85, 88, 78, 75, 90) # Assuming numeric scores for easier calculation
)

# Display the dataframes
print(product_sales_wide)
print(students_demographics)
print(student_grades)
```

---

### Task 2.1: New Variable Creation: Wide vs. Long (`product_sales` dataset)

This task demonstrates how creating new variables that depend on previous time periods is much easier in a long (tidy) format.

1.  **Analysis in Wide Format:** Using the `product_sales_wide` dataset, create new columns for the **year-over-year growth rate** for 2021 and 2022.
    * `Growth_2021`: `(Year_2021 - Year_2020) / Year_2020 * 100`
    * `Growth_2022`: `(Year_2022 - Year_2021) / Year_2021 * 100`

```{r}
product_sales_wide %>%
  mutate(
    Growth_2021 = (Year_2021 - Year_2020) / Year_2020 * 100,
    Growth_2022 = (Year_2022 - Year_2021) / Year_2021 * 100
  )
```

2.  **Reshape to Long Format:** Reshape `product_sales_wide` into a long format called `product_sales_long`. Pivot the year columns (`Year_2020`, `Year_2021`, `Year_2022`) into two new columns: `Year` and `Sales`. Make sure `Year` is numeric.

```{r}
product_sales_long <- product_sales_wide %>%
  pivot_longer(
    cols = starts_with("Year_"),
    names_to = "Year",
    values_to = "Sales"
  ) %>%
mutate(Year = as.numeric(str_remove(Year, "Year_")))
product_sales_long
```
3.  **Analysis in Long Format:** Using the `product_sales_long` dataset, calculate a single `Growth_Rate` column that represents the year-over-year growth for each product. You should use `group_by()` and `lag()`. The formula for growth rate is `(current_year_sales - previous_year_sales) / previous_year_sales * 100`.

```{r}
product_sales_long_growth <- product_sales_long %>% 
  group_by(product) %>%
  arrange(Year, .by_group = TRUE) %>%
  mutate(
    Growth_Rate = ((Sales - lag(Sales)) / lag(Sales)) * 100
  ) 
product_sales_long_growth
```

### Short Answer
Compare the code required to calculate the year-over-year growth rate in the wide format versus the long format. Which approach is more concise and scalable if you had many more years of data? Why is the long format generally preferred for this type of time-series calculation?

The wide format might be more concise and scale able since it's more has the product only listed once and shows only year 2021 and 2022 growth since 2020 is the base year. The long format is generally preferred since will automatically any years added on rather need to manually code each year for wide format.
---

### Task 2.2: Mutating Joins: Student Demographics and Grades

This task explores combining student demographic information with their academic performance. Pay close attention to how different join types handle students who may or may not have corresponding grade records.

1.  **Inner Join:** Perform an `inner_join()` to combine `students_demographics` with `student_grades` based on `student_id`. This will show students who have **both** demographic information and at least one grade record.
2.  **Left Join:** Perform a `left_join()` to combine `students_demographics` (left table) with `student_grades` based on `student_id`. This will keep **all students** from the demographic data and add their grade records where available.
3.  **Advanced Mutate (after Left Join):** After performing the left join, calculate the **average `grade_score` for each student**. This will require grouping by `student_id` and `student_name`.

```{r}
students_demographics %>%
  inner_join(student_grades, by = "student_id")  

students_demographics %>% 
  left_join(student_grades, by = "student_id") %>% 
  group_by(student_id, student_name) %>%
  mutate(avg_grade = mean(grade_score, na.rm = TRUE))
  

```

### Short Answer
Compare the number of rows and the content of the `inner_join()` and `left_join()` results. Specifically, identify which student(s) are present in one join but not the other, and explain why. What does the average grade calculation reveal about students with multiple grades or no grades?

Eve and Frank are not in inner join. It seems that they are not enrolled right now so they are not showing up with a course ID. With no grades means they are not enrolled. For more than one grade I think it shows they are taking more than one class.
---

### Task 2.3: Filtering Joins: Identifying Student Enrollment Status

This task focuses on using filtering joins to identify different categories of students based on their enrollment and grade records.

1.  **Enrolled Students:** Use a `semi_join()` to identify which students from `students_demographics` are actually enrolled in and have a grade record in `student_grades`. This should return only columns from `students_demographics`.
2.  **Students Without Grades:** Use an `anti_join()` to identify which students from `students_demographics` are in the system but currently do *not* have any grade records in `student_grades` (e.g., new students, or those who haven't completed courses yet). This should return only columns from `students_demographics`.
3.  **Grades Without Students:** Use an `anti_join()` to identify any grade records in `student_grades` that do *not* correspond to an existing student in `students_demographics` (e.g., a data entry error or a record for a past student no longer in the demographic system). This should return only columns from `student_grades`.

```{r}
enrolled_students <- students_demographics %>%
  inner_join(student_grades, by = "student_id")
enrolled_students

notenrolled_students <- students_demographics %>%
  anti_join(student_grades, by = "student_id")
notenrolled_students

grades_withno_students <- student_grades %>%
  anti_join(students_demographics, by = "student_id")
grades_withno_students

```

### Short Answer
Describe the distinct insights gained from each of the three filtering joins in this task. How do these joins help in data validation and understanding the completeness of your student records?

The first one shows which students are actually enrolled. The second shows students without grades so waiting on grade. The last one shows a grade but has no student attached to it. 

